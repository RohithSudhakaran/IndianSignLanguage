# ğŸ– Indian Sign Language Detector

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) ![Status: Stable](https://img.shields.io/badge/Status-Stable-brightgreen)

**Indian Sign Language Detector** is a real-time hand gesture recognition system that translates Indian Sign Language (ISL) into text using a webcam. It combines **MediaPipe** for hand tracking and a **TensorFlow CNN** for gesture classification.

*This project is lightweight, modular, and beginner-friendly. You can easily collect your own dataset, retrain the model, and extend it for more gestures.*

---

## âœ¨ Features

- ğŸ“· **Real-Time Detection**: Recognizes ISL gestures instantly using your webcam.  
- ğŸ– **One-Hand & Two-Hand Gestures**: Supports complex signs requiring multiple hands.  
- ğŸ§  **Custom CNN Model**: Trained on user-collected datasets for high accuracy.  
- ğŸ—ƒ **Dataset Collector**: Easily create and expand your gesture dataset.  
- ğŸ”„ **Smooth Predictions**: Includes stability checks to reduce flickering.  
- ğŸ›  **Extensible Design**: Add new gestures and retrain without rewriting code.  

---

## ğŸ“‚ Folder Structure

```
indian-sign-language/
â”‚
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ collect_data.py   # Script to collect gesture dataset
â”‚   â”œâ”€â”€ train_model.py    # Script to train CNN model
â”‚   â””â”€â”€ main.py           # Real-time gesture detection
â”‚
â”œâ”€â”€ models/               # Saved model and label encoder
â”‚   â”œâ”€â”€ hand_gesture_cnn_model.h5
â”‚   â””â”€â”€ label_encoder.pkl
â”‚
â”œâ”€â”€ dataset/              # Collected gesture CSV files
â”‚
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ .gitignore            # Files to ignore in Git
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸš€ Quick Start

### ğŸ–¥ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/<your-username>/indian-sign-language.git
   cd indian-sign-language
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   # Activate on Linux/Mac
   source venv/bin/activate
   # Activate on Windows
   venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

### ğŸ“ Usage

#### 1ï¸âƒ£ Collect Dataset
Run this script to capture gesture data:  
```bash
python src/collect_data.py
```

#### 2ï¸âƒ£ Train the Model
After collecting data, train your CNN model:  
```bash
python src/train_model.py
```

#### 3ï¸âƒ£ Run Gesture Detection
Start real-time gesture recognition:  
```bash
python src/main.py
```

---

## ğŸ›  Built With

- [MediaPipe](https://google.github.io/mediapipe/) â€“ Hand tracking
- [TensorFlow](https://www.tensorflow.org/) â€“ CNN model
- [OpenCV](https://opencv.org/) â€“ Webcam access
- [NumPy](https://numpy.org/) â€“ Data processing

---

## ğŸ™Œ Contributing

Contributions are welcome!  
1. Fork the repository  
2. Create your feature branch (`git checkout -b feature/awesome-feature`)  
3. Commit your changes (`git commit -m 'Add some awesome feature'`)  
4. Push to the branch (`git push origin feature/awesome-feature`)  
5. Open a Pull Request  

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Author

- **Rohith S**  
  [GitHub](https://github.com/<your-username>)
